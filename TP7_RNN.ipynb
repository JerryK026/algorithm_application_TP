{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RNN이 왜 중요한가?\n",
    "\n",
    "과거의 정보를 반영해 현재의 문제를 해결할 수가 있고, n개의 input을 통해 m개의 output을 내보낼 수 있어서 유연하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RNN은 일상생활 어디에 활용되는가?\n",
    "\n",
    "필기체 인식이나 음성 인식과 같이 시변적 특징을 가지는 데이터를 처리할 수 있다. \n",
    "\n",
    "출처 : https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNN을 활용가능한 알고리즘이나 패키지에는 무엇이 있는가?\n",
    "\n",
    "RNN의 단점중에는 멀리 있는 데이터의 정보는 반영되기 어렵다는 단점이 있다. 그 단점을 극복하기 위한 해결책 중 하나로 LSTM이 고안되었다. LSTM은 중요한 정보라고 생각되면 그 정보를 저장해놓고 비교하는 방식의 알고리즘이다.\n",
    "\n",
    "pytorch에 lstm을 구현한 라이브러리가 있다.\n",
    "\n",
    "출처 : https://pytorch.org/docs/master/generated/torch.nn.LSTM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RNN의 핵심 아이디어는 무엇인가?\n",
    "\n",
    "여러개의 데이터를 single vector로 만들기 위해서는 projection matrix W로  곱연산을 한 뒤, 축소된 data상에서 계산을 한다.\n",
    "![RNN_projection](./images/RNN_projection.png)\n",
    "\n",
    "이렇게 N to 1으로 진행하면 앞 정보로 뒤 정보를 유추할 수 있다. 여기서도 Markov property가 적용된다.\n",
    "![RNN_N_to_1](./images/RNN_N_to_1.png)\n",
    "\n",
    "이러한 N to 1 데이터를 순차적으로 sequence 형태로해서 가공하는 형식을 RNN이라고 한다. RNN의 특징으로는, 순서를 가지고 data를 집어넣는다. 그렇게 해서 이전에 넣었던 데이터는 후에도 계속해서 영향을 미친다. 이것이 RNN의 장점이다. 그러나, 단점으로는 문장의 길이가 길어지면(sequence가 길어지면) 과거의 데이터가 미치는 영향이 줄어들게 된다. 이걸 극복하기 위한 해결책으로는 LSTM, GRU 등이 있다. 또, sequence의 진행방향에 따라서 나중에 입력되는 data는 이전에 들어간 data에 영향을 미칠 수 없다. 이를 극복하기 위한 해결책으로는 Global Summarization(attention network)가 있다. RNN의 특징으로는 input과 output이 달라도 된다는 것이다.\n",
    "![RNN_encoding&decoding](./images/RNN_encoding&decoding.png)\n",
    "\n",
    "RNN은 4개의 형태로 나눌 수 있다. data를 순차적으로 넣는 forward rnn, 반대로 넣는 backward rnn, 하나는 forward로 넣고 하나는 backward로 넣어서 묶는 bidirectional rnn, rnn을 여러층으로 묶는 stacking rnn이 있다. stacking rnn은 데이터가 많으면 성능이 좋을 확률이 높기 때문에 우리가 쓰는 툴들에서는 기본적으로 stacking rnn을 지원하는 경우가 많다. bidrectional rnn의 경우, output의 수가 backward나 forward로 진행했을 때보다 2배 더 많다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
